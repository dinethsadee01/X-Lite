{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10109df9",
   "metadata": {},
   "source": [
    "## 1. Installation Verification\n",
    "\n",
    "Let's verify that all required packages are installed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6006f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python version\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Import core libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\nâœ… Core Libraries:\")\n",
    "print(f\"  PyTorch: {torch.__version__}\")\n",
    "print(f\"  TorchVision: {torchvision.__version__}\")\n",
    "print(f\"  NumPy: {np.__version__}\")\n",
    "print(f\"  Pandas: {pd.__version__}\")\n",
    "\n",
    "# Check CUDA availability\n",
    "print(f\"\\nðŸ–¥ï¸ Compute Device:\")\n",
    "print(f\"  CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"  GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(f\"  Running on CPU\")\n",
    "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        print(f\"  MPS (Apple Silicon) Available: True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41651ac0",
   "metadata": {},
   "source": [
    "## 2. Project Configuration\n",
    "\n",
    "Load the project configuration and disease labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f207ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import project configuration\n",
    "from config import Config, DISEASE_LABELS, NUM_CLASSES, DISEASE_DESCRIPTIONS\n",
    "\n",
    "print(\"ðŸ“ Project Structure:\")\n",
    "print(f\"  Root Directory: {Config.ROOT_DIR}\")\n",
    "print(f\"  Data Directory: {Config.DATA_DIR}\")\n",
    "print(f\"  Checkpoint Directory: {Config.CHECKPOINT_DIR}\")\n",
    "print(f\"  Logs Directory: {Config.LOGS_DIR}\")\n",
    "\n",
    "print(f\"\\nðŸ¥ Dataset Information:\")\n",
    "print(f\"  Dataset: {Config.DATASET_NAME}\")\n",
    "print(f\"  Number of Disease Classes: {NUM_CLASSES}\")\n",
    "print(f\"  Image Size: {Config.IMAGE_SIZE}x{Config.IMAGE_SIZE}\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ Disease Classes:\")\n",
    "for i, disease in enumerate(DISEASE_LABELS, 1):\n",
    "    print(f\"  {i:2d}. {disease}\")\n",
    "\n",
    "# Create necessary directories\n",
    "Config.create_directories()\n",
    "print(f\"\\nâœ… Directories created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d608085c",
   "metadata": {},
   "source": [
    "## 3. Dataset Status Check\n",
    "\n",
    "Check if the ChestX-ray14 dataset is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset availability\n",
    "print(\"ðŸ“Š Dataset Status:\")\n",
    "\n",
    "metadata_exists = Config.METADATA_CSV.exists()\n",
    "print(f\"  Metadata CSV: {'âœ… Found' if metadata_exists else 'âŒ Not Found'}\")\n",
    "print(f\"    Path: {Config.METADATA_CSV}\")\n",
    "\n",
    "raw_data_exists = Config.RAW_DATA_DIR.exists()\n",
    "print(f\"  Raw Data Directory: {'âœ… Found' if raw_data_exists else 'âŒ Not Found'}\")\n",
    "print(f\"    Path: {Config.RAW_DATA_DIR}\")\n",
    "\n",
    "if raw_data_exists:\n",
    "    # Count images\n",
    "    image_count = len(list(Config.RAW_DATA_DIR.glob(\"**/*.png\")))\n",
    "    print(f\"  Number of Images: {image_count:,}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Dataset not found!\")\n",
    "    print(\"\\nðŸ“¥ To download the dataset, run:\")\n",
    "    print(\"   python scripts/download_chestxray14.py --metadata-only  # Quick start\")\n",
    "    print(\"   python scripts/download_chestxray14.py                  # Full dataset (~45GB)\")\n",
    "\n",
    "# If metadata exists, load and show statistics\n",
    "if metadata_exists:\n",
    "    df = pd.read_csv(Config.METADATA_CSV)\n",
    "    print(f\"\\nðŸ“ˆ Dataset Statistics:\")\n",
    "    print(f\"  Total Images: {len(df):,}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f38f07",
   "metadata": {},
   "source": [
    "## 4. Model Architecture Options\n",
    "\n",
    "Let's explore the model architectures we'll experiment with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e799e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "print(\"ðŸ—ï¸ Available Model Architectures:\\n\")\n",
    "\n",
    "print(\"ðŸ“š TEACHER MODEL:\")\n",
    "print(f\"  Backbone: {Config.TEACHER_BACKBONE}\")\n",
    "print(f\"  Purpose: High-performance reference model for knowledge transfer\")\n",
    "\n",
    "print(\"\\nðŸŽ“ STUDENT MODEL BACKBONES (Lightweight):\")\n",
    "for i, backbone in enumerate(Config.STUDENT_BACKBONES, 1):\n",
    "    # Check if model exists in timm\n",
    "    is_available = backbone in timm.list_models()\n",
    "    status = \"âœ…\" if is_available else \"âš ï¸\"\n",
    "    print(f\"  {i}. {status} {backbone}\")\n",
    "\n",
    "print(\"\\nðŸ” ATTENTION MECHANISMS:\")\n",
    "for i, attention in enumerate(Config.ATTENTION_TYPES, 1):\n",
    "    print(f\"  {i}. {attention.upper()}\")\n",
    "    if attention == 'mhsa':\n",
    "        print(f\"     â†’ Multi-Head Self-Attention (standard Transformer)\")\n",
    "    elif attention == 'performer':\n",
    "        print(f\"     â†’ Performer (linear complexity attention)\")\n",
    "    elif attention == 'linear':\n",
    "        print(f\"     â†’ Linear Attention (efficient variant)\")\n",
    "    elif attention == 'none':\n",
    "        print(f\"     â†’ CNN-only baseline (no attention)\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Experiment Strategy:\")\n",
    "print(\"  We will test different combinations of:\")\n",
    "print(\"  â€¢ CNN Backbones Ã— Attention Mechanisms\")\n",
    "print(\"  â€¢ Temperature values for knowledge distillation\")\n",
    "print(\"  â€¢ Loss function weights (alpha)\")\n",
    "print(\"  â€¢ Learning rates and batch sizes\")\n",
    "print(\"\\n  Goal: Find optimal configuration for accuracy + efficiency!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35cf888",
   "metadata": {},
   "source": [
    "## 5. Training Configuration\n",
    "\n",
    "Review the baseline training hyperparameters (these will be optimized during experiments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ddfea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âš™ï¸ BASELINE TRAINING CONFIGURATION:\\n\")\n",
    "\n",
    "print(\"ðŸŽ“ Teacher Model:\")\n",
    "print(f\"  Epochs: {Config.TEACHER_EPOCHS}\")\n",
    "print(f\"  Batch Size: {Config.TEACHER_BATCH_SIZE}\")\n",
    "print(f\"  Learning Rate: {Config.TEACHER_LR}\")\n",
    "print(f\"  Weight Decay: {Config.TEACHER_WEIGHT_DECAY}\")\n",
    "\n",
    "print(\"\\nðŸƒ Student Model:\")\n",
    "print(f\"  Epochs: {Config.STUDENT_EPOCHS}\")\n",
    "print(f\"  Batch Size: {Config.STUDENT_BATCH_SIZE}\")\n",
    "print(f\"  Learning Rate: {Config.STUDENT_LR}\")\n",
    "print(f\"  Weight Decay: {Config.STUDENT_WEIGHT_DECAY}\")\n",
    "\n",
    "print(\"\\nðŸ”¥ Knowledge Distillation:\")\n",
    "print(f\"  Temperature (Ï„): {Config.KD_TEMPERATURE} (will test: 2, 4, 6, 8)\")\n",
    "print(f\"  Alpha (Î±): {Config.KD_ALPHA} (will test: 0.5, 0.7, 0.9)\")\n",
    "print(f\"    â€¢ Distillation Loss Weight: {Config.KD_ALPHA}\")\n",
    "print(f\"    â€¢ Hard Loss Weight: {1 - Config.KD_ALPHA}\")\n",
    "\n",
    "print(\"\\nðŸ“Š Data Configuration:\")\n",
    "print(f\"  Train Split: {Config.TRAIN_SPLIT * 100}%\")\n",
    "print(f\"  Validation Split: {Config.VAL_SPLIT * 100}%\")\n",
    "print(f\"  Test Split: {Config.TEST_SPLIT * 100}%\")\n",
    "\n",
    "print(\"\\nâ±ï¸ Training Settings:\")\n",
    "print(f\"  Early Stopping Patience: {Config.EARLY_STOPPING_PATIENCE} epochs\")\n",
    "print(f\"  Mixed Precision Training: {Config.MIXED_PRECISION}\")\n",
    "print(f\"  Gradient Clipping: {Config.GRADIENT_CLIP_NORM}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Note: These are baseline values.\")\n",
    "print(\"   We'll use hyperparameter optimization to find the best configuration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a6a80",
   "metadata": {},
   "source": [
    "## 6. Quick Backend API Test\n",
    "\n",
    "Test if the backend API can start (basic functionality check)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test backend services import\n",
    "try:\n",
    "    from backend.services.image_service import ImageService\n",
    "    from backend.services.prediction_service import PredictionService\n",
    "    from backend.services.report_service import ReportService\n",
    "    \n",
    "    print(\"âœ… Backend Services:\")\n",
    "    print(\"  â€¢ ImageService - âœ“ Ready\")\n",
    "    print(\"  â€¢ PredictionService - âœ“ Ready\")\n",
    "    print(\"  â€¢ ReportService - âœ“ Ready\")\n",
    "    \n",
    "    # Initialize services\n",
    "    image_service = ImageService()\n",
    "    prediction_service = PredictionService()\n",
    "    report_service = ReportService()\n",
    "    \n",
    "    print(\"\\nðŸ“¡ API Endpoints:\")\n",
    "    print(\"  â€¢ GET  /api/health - Health check\")\n",
    "    print(\"  â€¢ POST /api/upload - Upload X-ray image\")\n",
    "    print(\"  â€¢ POST /api/predict - Run prediction\")\n",
    "    print(\"  â€¢ POST /api/report/generate - Generate PDF report\")\n",
    "    \n",
    "    print(\"\\nðŸ’¡ To start the API server, run:\")\n",
    "    print(\"   cd backend && python app.py\")\n",
    "    print(\"\\n   Then visit: http://localhost:8000/api/docs\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âš ï¸ Backend import error: {e}\")\n",
    "    print(\"   Some dependencies may be missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294d7248",
   "metadata": {},
   "source": [
    "## 7. Next Steps ðŸŽ¯\n",
    "\n",
    "Based on your project status, here are the recommended next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798defdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ—ºï¸ PROJECT ROADMAP:\\n\")\n",
    "\n",
    "steps = [\n",
    "    {\n",
    "        \"phase\": \"Phase 1: Data Preparation\",\n",
    "        \"tasks\": [\n",
    "            \"Download ChestX-ray14 dataset\",\n",
    "            \"Run 01_data_exploration.ipynb\",\n",
    "            \"Analyze class distribution and imbalance\",\n",
    "            \"Test data augmentation strategies\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 2: Teacher Model\",\n",
    "        \"tasks\": [\n",
    "            \"Implement DenseNet121 teacher model\",\n",
    "            \"Train baseline teacher model\",\n",
    "            \"Evaluate teacher performance (target: AUC > 0.80)\",\n",
    "            \"Save best teacher checkpoint\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 3: Student Models\",\n",
    "        \"tasks\": [\n",
    "            \"Implement lightweight CNN backbones\",\n",
    "            \"Add transformer attention modules\",\n",
    "            \"Test different fusion strategies\",\n",
    "            \"Baseline student training (no distillation)\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 4: Knowledge Distillation\",\n",
    "        \"tasks\": [\n",
    "            \"Implement distillation loss function\",\n",
    "            \"Hyperparameter optimization (temperature, alpha)\",\n",
    "            \"Train student models with distillation\",\n",
    "            \"Compare student vs teacher performance\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 5: Optimization\",\n",
    "        \"tasks\": [\n",
    "            \"Model compression and pruning\",\n",
    "            \"Quantization for faster inference\",\n",
    "            \"Benchmark CPU inference speed\",\n",
    "            \"Optimize for <500ms latency\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 6: Web Application\",\n",
    "        \"tasks\": [\n",
    "            \"Complete backend API implementation\",\n",
    "            \"Build React frontend UI\",\n",
    "            \"Implement Grad-CAM visualization\",\n",
    "            \"PDF report generation\",\n",
    "            \"End-to-end testing\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 7: Deployment\",\n",
    "        \"tasks\": [\n",
    "            \"Dockerization\",\n",
    "            \"CPU-optimized deployment\",\n",
    "            \"Documentation and user guide\",\n",
    "            \"Final evaluation and thesis writing\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, step in enumerate(steps, 1):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"{i}. {step['phase']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for task in step['tasks']:\n",
    "        print(f\"   â˜ {task}\")\n",
    "    print()\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"ðŸš€ START HERE:\")\n",
    "print(f\"{'='*60}\")\n",
    "if not metadata_exists:\n",
    "    print(\"1. Download dataset: python scripts/download_chestxray14.py --metadata-only\")\n",
    "    print(\"2. Explore data: Open notebooks/01_data_exploration.ipynb\")\n",
    "else:\n",
    "    print(\"1. âœ… Dataset ready!\")\n",
    "    print(\"2. ðŸ“Š Next: Open notebooks/01_data_exploration.ipynb\")\n",
    "    print(\"3. ðŸ—ï¸ Then: Start implementing models in ml/models/\")\n",
    "    \n",
    "print(\"\\nðŸ“š Documentation:\")\n",
    "print(\"   â€¢ Setup Guide: docs/SETUP.md\")\n",
    "print(\"   â€¢ Model Architecture: docs/MODEL.md\")\n",
    "print(\"   â€¢ API Reference: docs/API.md\")\n",
    "\n",
    "print(\"\\nâœ¨ Good luck with your final year project! âœ¨\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
