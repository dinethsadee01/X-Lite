{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81fe45fd",
   "metadata": {},
   "source": [
    "# üöÄ X-Lite Colab Setup Guide\n",
    "\n",
    "**Google Colab Environment Setup for X-Lite Training**\n",
    "\n",
    "This notebook helps you set up Google Colab for training the X-Lite models with free GPU access.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã What This Notebook Does\n",
    "\n",
    "1. ‚úÖ Check GPU availability\n",
    "2. ‚úÖ Mount Google Drive (for data & checkpoints)\n",
    "3. ‚úÖ Clone X-Lite repository from GitHub\n",
    "4. ‚úÖ Install dependencies\n",
    "5. ‚úÖ Set up data paths\n",
    "6. ‚úÖ Verify setup\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Before You Start\n",
    "\n",
    "### Prerequisites:\n",
    "- [ ] GitHub account with X-Lite repository\n",
    "- [ ] Google Drive account\n",
    "- [ ] Dataset uploaded to Google Drive (optional - can upload later)\n",
    "\n",
    "### Recommended Drive Structure:\n",
    "```\n",
    "Google Drive/\n",
    "‚îî‚îÄ‚îÄ X-Lite/\n",
    "    ‚îú‚îÄ‚îÄ data/\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ Data_Entry_2017.csv\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ images/\n",
    "    ‚îú‚îÄ‚îÄ checkpoints/\n",
    "    ‚îî‚îÄ‚îÄ results/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Let's begin! Run each cell sequentially.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d8c486",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU Availability\n",
    "\n",
    "Verify that you have GPU access (T4, P100, or V100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check CUDA availability\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"\\n‚úì CUDA Available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    print(f\"‚úì GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úì CUDA Version: {torch.version.cuda}\")\n",
    "    \n",
    "    # Get GPU memory\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"‚úì GPU Memory: {gpu_memory:.2f} GB\")\n",
    "    \n",
    "    # Test GPU\n",
    "    x = torch.randn(1000, 1000).cuda()\n",
    "    y = x @ x.T\n",
    "    print(f\"‚úì GPU Test: Success!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ GPU is ready for training!\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚ö†Ô∏è  WARNING: GPU not available!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nüìù To enable GPU:\")\n",
    "    print(\"   1. Click 'Runtime' in menu\")\n",
    "    print(\"   2. Select 'Change runtime type'\")\n",
    "    print(\"   3. Choose 'T4 GPU' as Hardware accelerator\")\n",
    "    print(\"   4. Click 'Save'\")\n",
    "    print(\"   5. Re-run this cell\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c798e48d",
   "metadata": {},
   "source": [
    "## Step 2: Mount Google Drive\n",
    "\n",
    "Mount your Google Drive to access datasets and save checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d41cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MOUNTING GOOGLE DRIVE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify mount\n",
    "drive_path = '/content/drive/MyDrive'\n",
    "if os.path.exists(drive_path):\n",
    "    print(f\"\\n‚úì Google Drive mounted successfully!\")\n",
    "    print(f\"‚úì Drive path: {drive_path}\")\n",
    "    \n",
    "    # Create X-Lite folder structure if it doesn't exist\n",
    "    xlite_drive = os.path.join(drive_path, 'X-Lite')\n",
    "    os.makedirs(os.path.join(xlite_drive, 'data'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(xlite_drive, 'checkpoints'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(xlite_drive, 'results'), exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n‚úì Created/verified X-Lite folders in Drive:\")\n",
    "    print(f\"  ‚Ä¢ {xlite_drive}/data/\")\n",
    "    print(f\"  ‚Ä¢ {xlite_drive}/checkpoints/\")\n",
    "    print(f\"  ‚Ä¢ {xlite_drive}/results/\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ Google Drive is ready!\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Drive mount failed!\")\n",
    "    print(\"Please authorize the mount and re-run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abec730",
   "metadata": {},
   "source": [
    "## Step 3: Clone X-Lite Repository\n",
    "\n",
    "Clone your X-Lite repository from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ecd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CLONING X-LITE REPOSITORY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Repository URL (update with your GitHub username if needed)\n",
    "REPO_URL = \"https://github.com/dinethsadee01/X-Lite.git\"\n",
    "REPO_DIR = \"/content/X-Lite\"\n",
    "\n",
    "# Remove existing directory if present\n",
    "if os.path.exists(REPO_DIR):\n",
    "    print(f\"\\n‚ö†Ô∏è  Existing repo found. Removing...\")\n",
    "    shutil.rmtree(REPO_DIR)\n",
    "\n",
    "# Clone repository\n",
    "print(f\"\\nüì• Cloning from: {REPO_URL}\")\n",
    "!git clone {REPO_URL} {REPO_DIR}\n",
    "\n",
    "# Change to repo directory\n",
    "os.chdir(REPO_DIR)\n",
    "print(f\"\\n‚úì Changed directory to: {os.getcwd()}\")\n",
    "\n",
    "# Show repo structure\n",
    "print(\"\\nüìÅ Repository structure:\")\n",
    "!ls -la\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Repository cloned successfully!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüí° Tip: To pull latest changes later, run:\")\n",
    "print(\"   !git pull origin main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c485c8",
   "metadata": {},
   "source": [
    "## Step 4: Install Dependencies\n",
    "\n",
    "Install all required Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"INSTALLING DEPENDENCIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Install requirements\n",
    "print(\"\\nüì¶ Installing packages from requirements.txt...\")\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "# Install additional packages for Colab\n",
    "print(\"\\nüì¶ Installing Colab-specific packages...\")\n",
    "!pip install -q wandb  # For experiment tracking (optional)\n",
    "\n",
    "print(\"\\n‚úì Verifying installations...\")\n",
    "\n",
    "# Verify key packages\n",
    "import torch\n",
    "import torchvision\n",
    "import timm\n",
    "import albumentations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(f\"\\n‚úÖ Key Packages Verified:\")\n",
    "print(f\"  ‚Ä¢ PyTorch: {torch.__version__}\")\n",
    "print(f\"  ‚Ä¢ TorchVision: {torchvision.__version__}\")\n",
    "print(f\"  ‚Ä¢ timm: {timm.__version__}\")\n",
    "print(f\"  ‚Ä¢ albumentations: {albumentations.__version__}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ All dependencies installed!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dab351",
   "metadata": {},
   "source": [
    "## Step 5: Configure Data Paths\n",
    "\n",
    "Set up paths to link Google Drive data with the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aff0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURING DATA PATHS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Add project to Python path\n",
    "sys.path.insert(0, '/content/X-Lite')\n",
    "\n",
    "# Import config\n",
    "from config import Config\n",
    "\n",
    "# Google Drive paths\n",
    "DRIVE_XLITE = '/content/drive/MyDrive/X-Lite'\n",
    "DRIVE_DATA = os.path.join(DRIVE_XLITE, 'data')\n",
    "DRIVE_CHECKPOINTS = os.path.join(DRIVE_XLITE, 'checkpoints')\n",
    "DRIVE_RESULTS = os.path.join(DRIVE_XLITE, 'results')\n",
    "\n",
    "print(f\"\\nüìÇ Google Drive Paths:\")\n",
    "print(f\"  ‚Ä¢ Data: {DRIVE_DATA}\")\n",
    "print(f\"  ‚Ä¢ Checkpoints: {DRIVE_CHECKPOINTS}\")\n",
    "print(f\"  ‚Ä¢ Results: {DRIVE_RESULTS}\")\n",
    "\n",
    "# Create symbolic links (if data exists in Drive)\n",
    "if os.path.exists(DRIVE_DATA):\n",
    "    # Link data directory\n",
    "    if not os.path.exists('/content/X-Lite/data/raw'):\n",
    "        os.makedirs('/content/X-Lite/data', exist_ok=True)\n",
    "        os.system(f'ln -s {DRIVE_DATA} /content/X-Lite/data/raw')\n",
    "        print(f\"\\n‚úì Linked Drive data to repo\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Data not found in Drive. Upload dataset to: {DRIVE_DATA}\")\n",
    "    print(\"   You can upload later and re-run this cell.\")\n",
    "\n",
    "# Link checkpoint directory\n",
    "if not os.path.exists('/content/X-Lite/ml/models/checkpoints'):\n",
    "    os.makedirs('/content/X-Lite/ml/models', exist_ok=True)\n",
    "    os.system(f'ln -s {DRIVE_CHECKPOINTS} /content/X-Lite/ml/models/checkpoints')\n",
    "    print(f\"‚úì Linked Drive checkpoints to repo\")\n",
    "\n",
    "print(\"\\nüìä Project Configuration:\")\n",
    "print(f\"  ‚Ä¢ Dataset: {Config.DATASET_NAME}\")\n",
    "print(f\"  ‚Ä¢ Classes: {Config.NUM_CLASSES}\")\n",
    "print(f\"  ‚Ä¢ Image Size: {Config.IMAGE_SIZE}\")\n",
    "print(f\"  ‚Ä¢ Batch Size (Teacher): {Config.TEACHER_BATCH_SIZE}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Data paths configured!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdecd764",
   "metadata": {},
   "source": [
    "## Step 6: Verify Setup\n",
    "\n",
    "Run final checks to ensure everything is ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d508a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FINAL VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "checks = {\n",
    "    \"GPU Available\": torch.cuda.is_available(),\n",
    "    \"Google Drive Mounted\": os.path.exists('/content/drive/MyDrive'),\n",
    "    \"Repository Cloned\": os.path.exists('/content/X-Lite'),\n",
    "    \"Config Loaded\": 'Config' in dir(),\n",
    "    \"Data Directory\": os.path.exists('/content/X-Lite/data'),\n",
    "    \"Checkpoint Directory\": os.path.exists('/content/X-Lite/ml/models/checkpoints')\n",
    "}\n",
    "\n",
    "print(\"\\nüìã Setup Checklist:\\n\")\n",
    "all_passed = True\n",
    "for check, status in checks.items():\n",
    "    icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "    print(f\"  {icon} {check}\")\n",
    "    if not status:\n",
    "        all_passed = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "if all_passed:\n",
    "    print(\"üéâ ALL CHECKS PASSED! Ready to train!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nüöÄ Next Steps:\")\n",
    "    print(\"  1. Upload dataset to Google Drive (if not done)\")\n",
    "    print(\"  2. Open 01_train_teacher.ipynb\")\n",
    "    print(\"  3. Start training the teacher model!\")\n",
    "    print(\"\\nüí° Remember:\")\n",
    "    print(\"  ‚Ä¢ Save checkpoints regularly\")\n",
    "    print(\"  ‚Ä¢ Monitor training with TensorBoard/WandB\")\n",
    "    print(\"  ‚Ä¢ Session timeout: 12 hours (90 min idle)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  SOME CHECKS FAILED!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nPlease fix the issues above and re-run verification.\")\n",
    "    \n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Show system info\n",
    "print(\"\\nüìä System Information:\")\n",
    "!nvidia-smi --query-gpu=gpu_name,memory.total,memory.free --format=csv,noheader\n",
    "\n",
    "print(\"\\nüíæ Disk Space:\")\n",
    "!df -h /content\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea52d55",
   "metadata": {},
   "source": [
    "## üìù Optional: Set Up Weights & Biases (Experiment Tracking)\n",
    "\n",
    "Weights & Biases provides free experiment tracking and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27483a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Set up Weights & Biases for experiment tracking\n",
    "# Skip this cell if you don't want to use W&B\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"WEIGHTS & BIASES SETUP (Optional)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nüìä Weights & Biases helps you:\")\n",
    "    print(\"  ‚Ä¢ Track experiments automatically\")\n",
    "    print(\"  ‚Ä¢ Visualize metrics in real-time\")\n",
    "    print(\"  ‚Ä¢ Compare different runs\")\n",
    "    print(\"  ‚Ä¢ Share results easily\")\n",
    "    \n",
    "    print(\"\\nüîë To use W&B:\")\n",
    "    print(\"  1. Go to https://wandb.ai/authorize\")\n",
    "    print(\"  2. Copy your API key\")\n",
    "    print(\"  3. Run: wandb.login()\")\n",
    "    print(\"  4. Paste your API key when prompted\")\n",
    "    \n",
    "    print(\"\\nüí° Or skip this and use TensorBoard instead!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"W&B not installed. Run: !pip install wandb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e0ba70",
   "metadata": {},
   "source": [
    "## üéØ Summary & Next Steps\n",
    "\n",
    "### ‚úÖ What We've Set Up\n",
    "\n",
    "1. **GPU Environment**: Verified GPU access (T4/P100/V100)\n",
    "2. **Google Drive**: Mounted and configured folder structure\n",
    "3. **Repository**: Cloned X-Lite from GitHub\n",
    "4. **Dependencies**: Installed all required packages\n",
    "5. **Data Paths**: Linked Drive data to repository\n",
    "6. **Verification**: All systems ready!\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Next Notebooks (In Order)\n",
    "\n",
    "1. **`01_train_teacher.ipynb`** - Train DenseNet121 teacher model\n",
    "2. **`02_train_student.ipynb`** - Train lightweight student models\n",
    "3. **`03_knowledge_distillation.ipynb`** - Apply knowledge distillation\n",
    "4. **`04_gradcam_generation.ipynb`** - Generate Grad-CAM heatmaps\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Important Reminders\n",
    "\n",
    "**Before Training:**\n",
    "- ‚úÖ Upload dataset to Google Drive: `/X-Lite/data/`\n",
    "- ‚úÖ Check GPU quota (limited daily usage)\n",
    "- ‚úÖ Set session timeout reminder (12 hours max)\n",
    "\n",
    "**During Training:**\n",
    "- üíæ Save checkpoints every epoch to Drive\n",
    "- üìä Monitor with TensorBoard or W&B\n",
    "- ‚ö° Use mixed precision for faster training\n",
    "- üìù Log hyperparameters and results\n",
    "\n",
    "**After Training:**\n",
    "- üì• Download checkpoints from Drive\n",
    "- üìä Download training logs and metrics\n",
    "- üîÑ Push any code changes to GitHub\n",
    "- ‚úÖ Update local config with best hyperparameters\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Typical Workflow\n",
    "\n",
    "```\n",
    "VS Code (Local) ‚Üí GitHub ‚Üí Colab (Training) ‚Üí Google Drive ‚Üí VS Code (Local)\n",
    "    ‚Üì                                                              ‚Üì\n",
    "Write Code                                              Integrate Models\n",
    "    ‚Üì                                                              ‚Üì\n",
    "Commit & Push                                           Download Checkpoints\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üÜò Troubleshooting\n",
    "\n",
    "**Session Disconnects?**\n",
    "- Checkpoints are saved in Drive - just resume!\n",
    "- Re-run setup cells and continue from last epoch\n",
    "\n",
    "**Out of Memory?**\n",
    "- Reduce batch size in config\n",
    "- Use gradient accumulation\n",
    "- Clear CUDA cache: `torch.cuda.empty_cache()`\n",
    "\n",
    "**Slow Training?**\n",
    "- Enable mixed precision (AMP)\n",
    "- Reduce image size temporarily\n",
    "- Use DataLoader with num_workers=2\n",
    "\n",
    "---\n",
    "\n",
    "### üìû Resources\n",
    "\n",
    "- **Colab Pro**: $10/month for better GPU access & longer sessions\n",
    "- **Colab Documentation**: https://colab.research.google.com/\n",
    "- **X-Lite GitHub**: https://github.com/dinethsadee01/X-Lite\n",
    "- **Project Docs**: Check `docs/` folder in repo\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ You're all set! Happy training! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
