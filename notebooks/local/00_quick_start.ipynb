{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10109df9",
   "metadata": {},
   "source": [
    "## 1. Installation Verification\n",
    "\n",
    "Let's verify that all required packages are installed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6006f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.1 (tags/v3.13.1:0671451, Dec  3 2024, 19:06:28) [MSC v.1942 64 bit (AMD64)]\n",
      "Python executable: c:\\Users\\Asus\\x-lite-chest-xray\\.venv\\Scripts\\python.exe\n",
      "\n",
      "‚úÖ Core Libraries:\n",
      "  PyTorch: 2.9.1+cpu\n",
      "  TorchVision: 0.24.1+cpu\n",
      "  NumPy: 2.2.6\n",
      "  Pandas: 2.3.3\n",
      "\n",
      "üñ•Ô∏è Compute Device:\n",
      "  CUDA Available: False\n",
      "  Running on CPU\n"
     ]
    }
   ],
   "source": [
    "# Check Python version\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Import core libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n‚úÖ Core Libraries:\")\n",
    "print(f\"  PyTorch: {torch.__version__}\")\n",
    "print(f\"  TorchVision: {torchvision.__version__}\")\n",
    "print(f\"  NumPy: {np.__version__}\")\n",
    "print(f\"  Pandas: {pd.__version__}\")\n",
    "\n",
    "# Check CUDA availability\n",
    "print(f\"\\nüñ•Ô∏è Compute Device:\")\n",
    "print(f\"  CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"  GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(f\"  Running on CPU\")\n",
    "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        print(f\"  MPS (Apple Silicon) Available: True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41651ac0",
   "metadata": {},
   "source": [
    "## 2. Project Configuration\n",
    "\n",
    "Load the project configuration and disease labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f207ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Current Directory: c:\\Users\\Asus\\x-lite-chest-xray\\notebooks\\local\n",
      "üìÅ Project Root: c:\\Users\\Asus\\x-lite-chest-xray\n",
      "\n",
      "üìÅ Project Structure:\n",
      "  Root Directory: c:\\Users\\Asus\\x-lite-chest-xray\n",
      "  Data Directory: c:\\Users\\Asus\\x-lite-chest-xray\\data\n",
      "  Checkpoint Directory: c:\\Users\\Asus\\x-lite-chest-xray\\ml\\models\\checkpoints\n",
      "  Logs Directory: c:\\Users\\Asus\\x-lite-chest-xray\\logs\n",
      "\n",
      "üè• Dataset Information:\n",
      "  Dataset: ChestX-ray14\n",
      "  Number of Disease Classes: 14\n",
      "  Image Size: 224x224\n",
      "\n",
      "üìã Disease Classes:\n",
      "   1. Atelectasis\n",
      "   2. Cardiomegaly\n",
      "   3. Effusion\n",
      "   4. Infiltration\n",
      "   5. Mass\n",
      "   6. Nodule\n",
      "   7. Pneumonia\n",
      "   8. Pneumothorax\n",
      "   9. Consolidation\n",
      "  10. Edema\n",
      "  11. Emphysema\n",
      "  12. Fibrosis\n",
      "  13. Pleural_Thickening\n",
      "  14. Hernia\n",
      "\n",
      "‚úÖ Directories created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Add project root to path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"üìç Current Directory: {Path.cwd()}\")\n",
    "print(f\"üìÅ Project Root: {project_root}\")\n",
    "\n",
    "# Import project configuration\n",
    "from config import Config, DISEASE_LABELS, NUM_CLASSES, DISEASE_DESCRIPTIONS\n",
    "\n",
    "print(\"\\nüìÅ Project Structure:\")\n",
    "print(f\"  Root Directory: {Config.ROOT_DIR}\")\n",
    "print(f\"  Data Directory: {Config.DATA_DIR}\")\n",
    "print(f\"  Checkpoint Directory: {Config.CHECKPOINT_DIR}\")\n",
    "print(f\"  Logs Directory: {Config.LOGS_DIR}\")\n",
    "\n",
    "print(f\"\\nüè• Dataset Information:\")\n",
    "print(f\"  Dataset: {Config.DATASET_NAME}\")\n",
    "print(f\"  Number of Disease Classes: {NUM_CLASSES}\")\n",
    "print(f\"  Image Size: {Config.IMAGE_SIZE}x{Config.IMAGE_SIZE}\")\n",
    "\n",
    "print(f\"\\nüìã Disease Classes:\")\n",
    "for i, disease in enumerate(DISEASE_LABELS, 1):\n",
    "    print(f\"  {i:2d}. {disease}\")\n",
    "\n",
    "# Create necessary directories\n",
    "Config.create_directories()\n",
    "print(f\"\\n‚úÖ Directories created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d608085c",
   "metadata": {},
   "source": [
    "## 3. Dataset Status Check\n",
    "\n",
    "Check if the ChestX-ray14 dataset is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a646cee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset Status:\n",
      "  Metadata CSV: ‚úÖ Found\n",
      "    Path: c:\\Users\\Asus\\x-lite-chest-xray\\data\\Data_Entry_2017.csv\n",
      "  Raw Data Directory: ‚úÖ Found\n",
      "    Path: c:\\Users\\Asus\\x-lite-chest-xray\\data\\raw\n",
      "  Number of Images: 0\n",
      "\n",
      "üìà Dataset Statistics:\n",
      "  Total Images: 8\n",
      "  Columns: [' <!DOCTYPE html><html lang=\"en-US\"><head><meta name=\"robots\" content=\"noindex', ' nofollow\"><title>Box - Free Online File Storage', ' Internet File Sharing', ' Access Documents &amp; Files Anywhere', ' Backup Data', ' Share Files</title><link rel=\"shortcut icon\" href=\"/favicon.ico\" type=\"image/x-icon\" /><link href=\"https://cdn01.boxcdn.net/_assets/css/transition/style_not_found-pwZoby.css\" rel=\"stylesheet\" type=\"text/css\" media=\"screen\" /></head><body>   <div class=\"center\"> <a href=\"https://nihcc.app.box.com/\" class=\"logo\" ><img src=\"https://cdn01.boxcdn.net/_assets/img/not_found_box_logo-Czx5Gh.png\" border=\"0\" alt=\"Box\" title=\"Box\" /></a><div class=\"error_message   error_message_not_found      \"><h2>  This shared file or folder link has been removed.       </h2>   Think it‚Äôs a mistake? No worries: Just email the owner or get in touch with <a href=\"https://nihcc.app.box.com/help\" target=\"_blank\">Box support</a>. We‚Äôre here to help. Meantime', ' learn more about sharing files on Box ‚Äì and other features', ' benefits and solutions ‚Äì below. </div><div class=\"line line_top\"><!--  --></div><p class=\"block block_share\"> <a href=\"/signup\" class=\"head_link\" target=\"_blank\">Share your files</a><br />  Sign up for a free <a href=\"https://nihcc.app.box.com/signup\" target=\"_blank\">Box</a> account.</p><div class=\"line line_top\"><!--  --></div><p class=\"block block_learn\"> <a href=\"https://www.box.com/business/products-and-features/\" class=\"head_link\" target=\"_blank\">Explore Box</a><br /> Get to know our cool features', ' benefits and solutions.</p><div class=\"line\"><!--  --></div><p class=\"block block_help\"> <a href=\"https://support.box.com/hc/en-us/articles/200520998-What-are-Shared-Links-\" class=\"head_link\" target=\"_blank\"> Help With Shared Links</a> <br />Find out more today.</p><div class=\"line\"><!--  --></div></div><script type=\"text/javascript\" src=\"https://cdn01.boxcdn.net/_assets/js/vendor/jquery/jquery-1.12.4.patch-3-QBZWe7.js\"></script><script type=\"text/javascript\">']\n"
     ]
    }
   ],
   "source": [
    "# Check dataset availability\n",
    "print(\"üìä Dataset Status:\")\n",
    "\n",
    "metadata_exists = Config.METADATA_CSV.exists()\n",
    "print(f\"  Metadata CSV: {'‚úÖ Found' if metadata_exists else '‚ùå Not Found'}\")\n",
    "print(f\"    Path: {Config.METADATA_CSV}\")\n",
    "\n",
    "raw_data_exists = Config.RAW_DATA_DIR.exists()\n",
    "print(f\"  Raw Data Directory: {'‚úÖ Found' if raw_data_exists else '‚ùå Not Found'}\")\n",
    "print(f\"    Path: {Config.RAW_DATA_DIR}\")\n",
    "\n",
    "if raw_data_exists:\n",
    "    # Count images\n",
    "    image_count = len(list(Config.RAW_DATA_DIR.glob(\"**/*.png\")))\n",
    "    print(f\"  Number of Images: {image_count:,}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Dataset not found!\")\n",
    "    print(\"\\nüì• To download the dataset, run:\")\n",
    "    print(\"   python scripts/download_chestxray14.py --metadata-only  # Quick start\")\n",
    "    print(\"   python scripts/download_chestxray14.py                  # Full dataset (~45GB)\")\n",
    "\n",
    "# If metadata exists, load and show statistics\n",
    "if metadata_exists:\n",
    "    df = pd.read_csv(Config.METADATA_CSV)\n",
    "    print(f\"\\nüìà Dataset Statistics:\")\n",
    "    print(f\"  Total Images: {len(df):,}\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f38f07",
   "metadata": {},
   "source": [
    "## 4. Model Architecture Options\n",
    "\n",
    "Let's explore the model architectures we'll experiment with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e799e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\x-lite-chest-xray\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Available Model Architectures:\n",
      "\n",
      "üìö TEACHER MODEL:\n",
      "  Backbone: densenet121\n",
      "  Purpose: High-performance reference model for knowledge transfer\n",
      "\n",
      "üéì STUDENT MODEL BACKBONES (Lightweight):\n",
      "  1. ‚úÖ efficientnet_b0\n",
      "  2. ‚úÖ convnext_tiny\n",
      "  3. ‚úÖ mobilenetv3_large_100\n",
      "  4. ‚úÖ resnet50\n",
      "\n",
      "üîç ATTENTION MECHANISMS:\n",
      "  1. MHSA\n",
      "     ‚Üí Multi-Head Self-Attention (standard Transformer)\n",
      "  2. PERFORMER\n",
      "     ‚Üí Performer (linear complexity attention)\n",
      "  3. LINEAR\n",
      "     ‚Üí Linear Attention (efficient variant)\n",
      "  4. NONE\n",
      "     ‚Üí CNN-only baseline (no attention)\n",
      "\n",
      "üí° Experiment Strategy:\n",
      "  We will test different combinations of:\n",
      "  ‚Ä¢ CNN Backbones √ó Attention Mechanisms\n",
      "  ‚Ä¢ Temperature values for knowledge distillation\n",
      "  ‚Ä¢ Loss function weights (alpha)\n",
      "  ‚Ä¢ Learning rates and batch sizes\n",
      "\n",
      "  Goal: Find optimal configuration for accuracy + efficiency!\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "print(\"üèóÔ∏è Available Model Architectures:\\n\")\n",
    "\n",
    "print(\"üìö TEACHER MODEL:\")\n",
    "print(f\"  Backbone: {Config.TEACHER_BACKBONE}\")\n",
    "print(f\"  Purpose: High-performance reference model for knowledge transfer\")\n",
    "\n",
    "print(\"\\nüéì STUDENT MODEL BACKBONES (Lightweight):\")\n",
    "for i, backbone in enumerate(Config.STUDENT_BACKBONES, 1):\n",
    "    # Check if model exists in timm\n",
    "    is_available = backbone in timm.list_models()\n",
    "    status = \"‚úÖ\" if is_available else \"‚ö†Ô∏è\"\n",
    "    print(f\"  {i}. {status} {backbone}\")\n",
    "\n",
    "print(\"\\nüîç ATTENTION MECHANISMS:\")\n",
    "for i, attention in enumerate(Config.ATTENTION_TYPES, 1):\n",
    "    print(f\"  {i}. {attention.upper()}\")\n",
    "    if attention == 'mhsa':\n",
    "        print(f\"     ‚Üí Multi-Head Self-Attention (standard Transformer)\")\n",
    "    elif attention == 'performer':\n",
    "        print(f\"     ‚Üí Performer (linear complexity attention)\")\n",
    "    elif attention == 'linear':\n",
    "        print(f\"     ‚Üí Linear Attention (efficient variant)\")\n",
    "    elif attention == 'none':\n",
    "        print(f\"     ‚Üí CNN-only baseline (no attention)\")\n",
    "\n",
    "print(\"\\nüí° Experiment Strategy:\")\n",
    "print(\"  We will test different combinations of:\")\n",
    "print(\"  ‚Ä¢ CNN Backbones √ó Attention Mechanisms\")\n",
    "print(\"  ‚Ä¢ Temperature values for knowledge distillation\")\n",
    "print(\"  ‚Ä¢ Loss function weights (alpha)\")\n",
    "print(\"  ‚Ä¢ Learning rates and batch sizes\")\n",
    "print(\"\\n  Goal: Find optimal configuration for accuracy + efficiency!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35cf888",
   "metadata": {},
   "source": [
    "## 5. Training Configuration\n",
    "\n",
    "Review the baseline training hyperparameters (these will be optimized during experiments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ddfea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è BASELINE TRAINING CONFIGURATION:\n",
      "\n",
      "üéì Teacher Model:\n",
      "  Epochs: 30\n",
      "  Batch Size: 32\n",
      "  Learning Rate: 0.0001\n",
      "  Weight Decay: 0.0001\n",
      "\n",
      "üèÉ Student Model:\n",
      "  Epochs: 40\n",
      "  Batch Size: 64\n",
      "  Learning Rate: 0.001\n",
      "  Weight Decay: 0.0001\n",
      "\n",
      "üî• Knowledge Distillation:\n",
      "  Temperature (œÑ): 4.0 (will test: 2, 4, 6, 8)\n",
      "  Alpha (Œ±): 0.7 (will test: 0.5, 0.7, 0.9)\n",
      "    ‚Ä¢ Distillation Loss Weight: 0.7\n",
      "    ‚Ä¢ Hard Loss Weight: 0.30000000000000004\n",
      "\n",
      "üìä Data Configuration:\n",
      "  Train Split: 70.0%\n",
      "  Validation Split: 15.0%\n",
      "  Test Split: 15.0%\n",
      "\n",
      "‚è±Ô∏è Training Settings:\n",
      "  Early Stopping Patience: 7 epochs\n",
      "  Mixed Precision Training: True\n",
      "  Gradient Clipping: 1.0\n",
      "\n",
      "üí° Note: These are baseline values.\n",
      "   We'll use hyperparameter optimization to find the best configuration!\n"
     ]
    }
   ],
   "source": [
    "print(\"‚öôÔ∏è BASELINE TRAINING CONFIGURATION:\\n\")\n",
    "\n",
    "print(\"üéì Teacher Model:\")\n",
    "print(f\"  Epochs: {Config.TEACHER_EPOCHS}\")\n",
    "print(f\"  Batch Size: {Config.TEACHER_BATCH_SIZE}\")\n",
    "print(f\"  Learning Rate: {Config.TEACHER_LR}\")\n",
    "print(f\"  Weight Decay: {Config.TEACHER_WEIGHT_DECAY}\")\n",
    "\n",
    "print(\"\\nüèÉ Student Model:\")\n",
    "print(f\"  Epochs: {Config.STUDENT_EPOCHS}\")\n",
    "print(f\"  Batch Size: {Config.STUDENT_BATCH_SIZE}\")\n",
    "print(f\"  Learning Rate: {Config.STUDENT_LR}\")\n",
    "print(f\"  Weight Decay: {Config.STUDENT_WEIGHT_DECAY}\")\n",
    "\n",
    "print(\"\\nüî• Knowledge Distillation:\")\n",
    "print(f\"  Temperature (œÑ): {Config.KD_TEMPERATURE} (will test: 2, 4, 6, 8)\")\n",
    "print(f\"  Alpha (Œ±): {Config.KD_ALPHA} (will test: 0.5, 0.7, 0.9)\")\n",
    "print(f\"    ‚Ä¢ Distillation Loss Weight: {Config.KD_ALPHA}\")\n",
    "print(f\"    ‚Ä¢ Hard Loss Weight: {1 - Config.KD_ALPHA}\")\n",
    "\n",
    "print(\"\\nüìä Data Configuration:\")\n",
    "print(f\"  Train Split: {Config.TRAIN_SPLIT * 100}%\")\n",
    "print(f\"  Validation Split: {Config.VAL_SPLIT * 100}%\")\n",
    "print(f\"  Test Split: {Config.TEST_SPLIT * 100}%\")\n",
    "\n",
    "print(\"\\n‚è±Ô∏è Training Settings:\")\n",
    "print(f\"  Early Stopping Patience: {Config.EARLY_STOPPING_PATIENCE} epochs\")\n",
    "print(f\"  Mixed Precision Training: {Config.MIXED_PRECISION}\")\n",
    "print(f\"  Gradient Clipping: {Config.GRADIENT_CLIP_NORM}\")\n",
    "\n",
    "print(\"\\nüí° Note: These are baseline values.\")\n",
    "print(\"   We'll use hyperparameter optimization to find the best configuration!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a6a80",
   "metadata": {},
   "source": [
    "## 6. Quick Backend API Test\n",
    "\n",
    "Test if the backend API can start (basic functionality check)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c73d5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Backend Services:\n",
      "  ‚Ä¢ ImageService - ‚úì Ready\n",
      "  ‚Ä¢ PredictionService - ‚úì Ready\n",
      "  ‚Ä¢ ReportService - ‚úì Ready\n",
      "\n",
      "üì° API Endpoints:\n",
      "  ‚Ä¢ GET  /api/health - Health check\n",
      "  ‚Ä¢ POST /api/upload - Upload X-ray image\n",
      "  ‚Ä¢ POST /api/predict - Run prediction\n",
      "  ‚Ä¢ POST /api/report/generate - Generate PDF report\n",
      "\n",
      "üí° To start the API server, run:\n",
      "   cd backend && python app.py\n",
      "\n",
      "   Then visit: http://localhost:8000/api/docs\n"
     ]
    }
   ],
   "source": [
    "# Test backend services import\n",
    "try:\n",
    "    from backend.services.image_service import ImageService\n",
    "    from backend.services.prediction_service import PredictionService\n",
    "    from backend.services.report_service import ReportService\n",
    "    \n",
    "    print(\"‚úÖ Backend Services:\")\n",
    "    print(\"  ‚Ä¢ ImageService - ‚úì Ready\")\n",
    "    print(\"  ‚Ä¢ PredictionService - ‚úì Ready\")\n",
    "    print(\"  ‚Ä¢ ReportService - ‚úì Ready\")\n",
    "    \n",
    "    # Initialize services\n",
    "    image_service = ImageService()\n",
    "    prediction_service = PredictionService()\n",
    "    report_service = ReportService()\n",
    "    \n",
    "    print(\"\\nüì° API Endpoints:\")\n",
    "    print(\"  ‚Ä¢ GET  /api/health - Health check\")\n",
    "    print(\"  ‚Ä¢ POST /api/upload - Upload X-ray image\")\n",
    "    print(\"  ‚Ä¢ POST /api/predict - Run prediction\")\n",
    "    print(\"  ‚Ä¢ POST /api/report/generate - Generate PDF report\")\n",
    "    \n",
    "    print(\"\\nüí° To start the API server, run:\")\n",
    "    print(\"   cd backend && python app.py\")\n",
    "    print(\"\\n   Then visit: http://localhost:8000/api/docs\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Backend import error: {e}\")\n",
    "    print(\"   Some dependencies may be missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294d7248",
   "metadata": {},
   "source": [
    "## 7. Next Steps üéØ\n",
    "\n",
    "Based on your project status, here are the recommended next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "798defdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üó∫Ô∏è PROJECT ROADMAP:\n",
      "\n",
      "============================================================\n",
      "1. Phase 1: Data Preparation\n",
      "============================================================\n",
      "   ‚òê Download ChestX-ray14 dataset\n",
      "   ‚òê Run 01_data_exploration.ipynb\n",
      "   ‚òê Analyze class distribution and imbalance\n",
      "   ‚òê Test data augmentation strategies\n",
      "\n",
      "============================================================\n",
      "2. Phase 2: Teacher Model\n",
      "============================================================\n",
      "   ‚òê Implement DenseNet121 teacher model\n",
      "   ‚òê Train baseline teacher model\n",
      "   ‚òê Evaluate teacher performance (target: AUC > 0.80)\n",
      "   ‚òê Save best teacher checkpoint\n",
      "\n",
      "============================================================\n",
      "3. Phase 3: Student Models\n",
      "============================================================\n",
      "   ‚òê Implement lightweight CNN backbones\n",
      "   ‚òê Add transformer attention modules\n",
      "   ‚òê Test different fusion strategies\n",
      "   ‚òê Baseline student training (no distillation)\n",
      "\n",
      "============================================================\n",
      "4. Phase 4: Knowledge Distillation\n",
      "============================================================\n",
      "   ‚òê Implement distillation loss function\n",
      "   ‚òê Hyperparameter optimization (temperature, alpha)\n",
      "   ‚òê Train student models with distillation\n",
      "   ‚òê Compare student vs teacher performance\n",
      "\n",
      "============================================================\n",
      "5. Phase 5: Optimization\n",
      "============================================================\n",
      "   ‚òê Model compression and pruning\n",
      "   ‚òê Quantization for faster inference\n",
      "   ‚òê Benchmark CPU inference speed\n",
      "   ‚òê Optimize for <500ms latency\n",
      "\n",
      "============================================================\n",
      "6. Phase 6: Web Application\n",
      "============================================================\n",
      "   ‚òê Complete backend API implementation\n",
      "   ‚òê Build React frontend UI\n",
      "   ‚òê Implement Grad-CAM visualization\n",
      "   ‚òê PDF report generation\n",
      "   ‚òê End-to-end testing\n",
      "\n",
      "============================================================\n",
      "7. Phase 7: Deployment\n",
      "============================================================\n",
      "   ‚òê Dockerization\n",
      "   ‚òê CPU-optimized deployment\n",
      "   ‚òê Documentation and user guide\n",
      "   ‚òê Final evaluation and thesis writing\n",
      "\n",
      "============================================================\n",
      "üöÄ START HERE:\n",
      "============================================================\n",
      "1. ‚úÖ Dataset ready!\n",
      "2. üìä Next: Open notebooks/01_data_exploration.ipynb\n",
      "3. üèóÔ∏è Then: Start implementing models in ml/models/\n",
      "\n",
      "üìö Documentation:\n",
      "   ‚Ä¢ Setup Guide: docs/SETUP.md\n",
      "   ‚Ä¢ Model Architecture: docs/MODEL.md\n",
      "   ‚Ä¢ API Reference: docs/API.md\n",
      "\n",
      "‚ú® Good luck with your final year project! ‚ú®\n"
     ]
    }
   ],
   "source": [
    "print(\"üó∫Ô∏è PROJECT ROADMAP:\\n\")\n",
    "\n",
    "steps = [\n",
    "    {\n",
    "        \"phase\": \"Phase 1: Data Preparation\",\n",
    "        \"tasks\": [\n",
    "            \"Download ChestX-ray14 dataset\",\n",
    "            \"Run 01_data_exploration.ipynb\",\n",
    "            \"Analyze class distribution and imbalance\",\n",
    "            \"Test data augmentation strategies\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 2: Teacher Model\",\n",
    "        \"tasks\": [\n",
    "            \"Implement DenseNet121 teacher model\",\n",
    "            \"Train baseline teacher model\",\n",
    "            \"Evaluate teacher performance (target: AUC > 0.80)\",\n",
    "            \"Save best teacher checkpoint\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 3: Student Models\",\n",
    "        \"tasks\": [\n",
    "            \"Implement lightweight CNN backbones\",\n",
    "            \"Add transformer attention modules\",\n",
    "            \"Test different fusion strategies\",\n",
    "            \"Baseline student training (no distillation)\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 4: Knowledge Distillation\",\n",
    "        \"tasks\": [\n",
    "            \"Implement distillation loss function\",\n",
    "            \"Hyperparameter optimization (temperature, alpha)\",\n",
    "            \"Train student models with distillation\",\n",
    "            \"Compare student vs teacher performance\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 5: Optimization\",\n",
    "        \"tasks\": [\n",
    "            \"Model compression and pruning\",\n",
    "            \"Quantization for faster inference\",\n",
    "            \"Benchmark CPU inference speed\",\n",
    "            \"Optimize for <500ms latency\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 6: Web Application\",\n",
    "        \"tasks\": [\n",
    "            \"Complete backend API implementation\",\n",
    "            \"Build React frontend UI\",\n",
    "            \"Implement Grad-CAM visualization\",\n",
    "            \"PDF report generation\",\n",
    "            \"End-to-end testing\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"phase\": \"Phase 7: Deployment\",\n",
    "        \"tasks\": [\n",
    "            \"Dockerization\",\n",
    "            \"CPU-optimized deployment\",\n",
    "            \"Documentation and user guide\",\n",
    "            \"Final evaluation and thesis writing\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, step in enumerate(steps, 1):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"{i}. {step['phase']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for task in step['tasks']:\n",
    "        print(f\"   ‚òê {task}\")\n",
    "    print()\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"üöÄ START HERE:\")\n",
    "print(f\"{'='*60}\")\n",
    "if not metadata_exists:\n",
    "    print(\"1. Download dataset: python scripts/download_chestxray14.py --metadata-only\")\n",
    "    print(\"2. Explore data: Open notebooks/01_data_exploration.ipynb\")\n",
    "else:\n",
    "    print(\"1. ‚úÖ Dataset ready!\")\n",
    "    print(\"2. üìä Next: Open notebooks/01_data_exploration.ipynb\")\n",
    "    print(\"3. üèóÔ∏è Then: Start implementing models in ml/models/\")\n",
    "    \n",
    "print(\"\\nüìö Documentation:\")\n",
    "print(\"   ‚Ä¢ Setup Guide: docs/SETUP.md\")\n",
    "print(\"   ‚Ä¢ Model Architecture: docs/MODEL.md\")\n",
    "print(\"   ‚Ä¢ API Reference: docs/API.md\")\n",
    "\n",
    "print(\"\\n‚ú® Good luck with your final year project! ‚ú®\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
