{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e510660e",
   "metadata": {},
   "source": [
    "# Chest X-Ray Dataset Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Objective**: Comprehensive analysis of ChestX-ray14 dataset to understand class distribution, imbalance, and inform preprocessing/training strategy.\n",
    "\n",
    "**Dataset**: NIH ChestX-ray14 (112,120 frontal-view X-rays, 14 disease classes, multi-label)\n",
    "\n",
    "**Date**: January 21, 2026\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf12132",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75006620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set project root\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import project config\n",
    "from config import Config, DISEASE_LABELS, NUM_CLASSES\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Number of Disease Classes: {NUM_CLASSES}\")\n",
    "print(f\"Disease Classes: {DISEASE_LABELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6040d6bc",
   "metadata": {},
   "source": [
    "## 2. Load Dataset Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb8721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata CSV\n",
    "metadata_path = Config.METADATA_CSV\n",
    "print(f\"Loading metadata from: {metadata_path}\")\n",
    "\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "print(f\"\\nâœ“ Dataset loaded successfully!\")\n",
    "print(f\"  Total records: {len(df):,}\")\n",
    "print(f\"  Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1004a",
   "metadata": {},
   "source": [
    "## 3. Dataset Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce88275",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DATASET STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Column names in metadata\n",
    "print(f\"\\nDataframe Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(f\"\\nBasic Statistics:\")\n",
    "print(f\"  Total Images: {len(df):,}\")\n",
    "print(f\"  Unique Image IDs: {df.iloc[:, 0].nunique():,}\")\n",
    "print(f\"  Patients: {df.iloc[:, 4].nunique():,}\" if df.shape[1] > 4 else \"  N/A\")\n",
    "\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff71b131",
   "metadata": {},
   "source": [
    "## 4. Disease Label Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31abc8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse disease labels (column 1 contains pipe-separated labels)\n",
    "label_column = df.iloc[:, 1]  # Typically column 1 (index 1) has labels\n",
    "\n",
    "# Count each disease occurrence\n",
    "disease_counts = {}\n",
    "total_labels = 0\n",
    "images_with_no_finding = 0\n",
    "\n",
    "for labels in label_column:\n",
    "    if pd.isna(labels):\n",
    "        images_with_no_finding += 1\n",
    "        continue\n",
    "    \n",
    "    label_str = str(labels).strip()\n",
    "    \n",
    "    if label_str == 'No Finding':\n",
    "        images_with_no_finding += 1\n",
    "        total_labels += 1\n",
    "    else:\n",
    "        # Split by pipe and count\n",
    "        diseases = [d.strip() for d in label_str.split('|')]\n",
    "        for disease in diseases:\n",
    "            disease_counts[disease] = disease_counts.get(disease, 0) + 1\n",
    "            total_labels += 1\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DISEASE LABEL DISTRIBUTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sort by count\n",
    "sorted_diseases = sorted(disease_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"\\nTotal Disease Occurrences: {total_labels:,}\")\n",
    "print(f\"Images with 'No Finding': {images_with_no_finding:,} ({images_with_no_finding/len(df)*100:.1f}%)\")\n",
    "print(f\"\\nDisease Counts:\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Rank':<6} {'Disease':<30} {'Count':<12} {'Percentage':<12}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for rank, (disease, count) in enumerate(sorted_diseases, 1):\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{rank:<6} {disease:<30} {count:<12,} {percentage:<12.2f}%\")\n",
    "\n",
    "print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df445f",
   "metadata": {},
   "source": [
    "## 5. Class Imbalance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate imbalance metrics\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASS IMBALANCE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get counts\n",
    "counts = np.array([count for _, count in sorted_diseases])\n",
    "\n",
    "# Metrics\n",
    "min_count = counts.min()\n",
    "max_count = counts.max()\n",
    "imbalance_ratio = max_count / min_count\n",
    "\n",
    "print(f\"\\nImbalance Metrics:\")\n",
    "print(f\"  Max count: {max_count:,}\")\n",
    "print(f\"  Min count: {min_count:,}\")\n",
    "print(f\"  Imbalance ratio (max/min): {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "# Gini coefficient (measure of inequality)\n",
    "def gini_coefficient(counts):\n",
    "    n = len(counts)\n",
    "    sorted_counts = np.sort(counts)\n",
    "    cumsum = np.cumsum(sorted_counts)\n",
    "    gini = (2 * np.sum(np.arange(1, n+1) * sorted_counts)) / (n * np.sum(sorted_counts)) - (n + 1) / n\n",
    "    return gini\n",
    "\n",
    "gini = gini_coefficient(counts)\n",
    "print(f\"  Gini coefficient: {gini:.4f} (0=perfect balance, 1=extreme imbalance)\")\n",
    "\n",
    "# Effective number of samples (recommended for imbalanced data)\n",
    "def effective_num_samples(counts, beta=0.9999):\n",
    "    return (1 - beta) / (1 - (beta ** counts))\n",
    "\n",
    "effective_counts = effective_num_samples(counts)\n",
    "print(f\"  Effective number of samples (Î²=0.9999):\")\n",
    "for (disease, _), eff in zip(sorted_diseases, effective_counts):\n",
    "    print(f\"    {disease}: {eff:.0f}\")\n",
    "\n",
    "# Class weights (inverse frequency)\n",
    "class_weights = {disease: len(df) / (count * len(sorted_diseases)) \n",
    "                 for disease, count in sorted_diseases}\n",
    "\n",
    "print(f\"\\n  Recommended class weights (inverse frequency):\")\n",
    "for disease, weight in sorted(class_weights.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"    {disease}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0389ed2",
   "metadata": {},
   "source": [
    "## 6. Multi-Label Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count diseases per image\n",
    "diseases_per_image = []\n",
    "\n",
    "for labels in label_column:\n",
    "    if pd.isna(labels):\n",
    "        diseases_per_image.append(0)\n",
    "    else:\n",
    "        label_str = str(labels).strip()\n",
    "        if label_str == 'No Finding':\n",
    "            diseases_per_image.append(0)\n",
    "        else:\n",
    "            disease_count = len([d.strip() for d in label_str.split('|') if d.strip()])\n",
    "            diseases_per_image.append(disease_count)\n",
    "\n",
    "df['num_diseases'] = diseases_per_image\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MULTI-LABEL STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nDiseases per image distribution:\")\n",
    "dist = df['num_diseases'].value_counts().sort_index()\n",
    "for num_diseases, count in dist.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {num_diseases} disease(s): {count:>6,} images ({percentage:>5.1f}%)\")\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Mean diseases per image: {df['num_diseases'].mean():.2f}\")\n",
    "print(f\"  Median diseases per image: {df['num_diseases'].median():.0f}\")\n",
    "print(f\"  Max diseases per image: {df['num_diseases'].max():.0f}\")\n",
    "print(f\"  Min diseases per image: {df['num_diseases'].min():.0f}\")\n",
    "print(f\"  Std dev: {df['num_diseases'].std():.2f}\")\n",
    "\n",
    "print(f\"\\nCritical finding:\")\n",
    "no_disease = len(df[df['num_diseases'] == 0])\n",
    "multi_disease = len(df[df['num_diseases'] > 1])\n",
    "print(f\"  Normal (0 diseases): {no_disease:,} ({no_disease/len(df)*100:.1f}%)\")\n",
    "print(f\"  Multi-pathology (>1 disease): {multi_disease:,} ({multi_disease/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6282a86",
   "metadata": {},
   "source": [
    "## 7. Disease Co-Occurrence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a852f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build co-occurrence matrix\n",
    "from itertools import combinations\n",
    "\n",
    "co_occurrence = {}\n",
    "\n",
    "for labels in label_column:\n",
    "    if pd.isna(labels):\n",
    "        continue\n",
    "    \n",
    "    label_str = str(labels).strip()\n",
    "    if label_str == 'No Finding':\n",
    "        continue\n",
    "    \n",
    "    diseases = [d.strip() for d in label_str.split('|')]\n",
    "    \n",
    "    # Count pairs\n",
    "    for disease_pair in combinations(sorted(diseases), 2):\n",
    "        key = tuple(sorted(disease_pair))\n",
    "        co_occurrence[key] = co_occurrence.get(key, 0) + 1\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DISEASE CO-OCCURRENCE (Top 15 pairs)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "sorted_pairs = sorted(co_occurrence.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "\n",
    "print(f\"\\n{'Rank':<6} {'Disease 1':<20} {'Disease 2':<20} {'Co-occurrence':<12}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for rank, ((disease1, disease2), count) in enumerate(sorted_pairs, 1):\n",
    "    print(f\"{rank:<6} {disease1:<20} {disease2:<20} {count:<12,}\")\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(f\"\\nTotal unique disease pairs: {len(co_occurrence)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff4b3ad",
   "metadata": {},
   "source": [
    "## 8. Image File Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6f6344",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IMAGE FILE VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "image_dir = Config.RAW_DATA_DIR / 'images'\n",
    "\n",
    "if not image_dir.exists():\n",
    "    print(f\"\\nâš ï¸  Image directory not found: {image_dir}\")\n",
    "    print(f\"Expected path: {Config.RAW_DATA_DIR}\")\n",
    "    print(f\"\\nPlease ensure images are extracted to: {image_dir}\")\n",
    "else:\n",
    "    # Count actual image files\n",
    "    image_files = list(image_dir.glob(\"*.png\"))\n",
    "    image_count = len(image_files)\n",
    "    \n",
    "    print(f\"\\nâœ“ Image directory found: {image_dir}\")\n",
    "    print(f\"  Total image files: {image_count:,}\")\n",
    "    print(f\"  Expected from metadata: {len(df):,}\")\n",
    "    \n",
    "    if image_count == len(df):\n",
    "        print(f\"  âœ“ Counts match!\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸  Count mismatch! ({len(df) - image_count:,} missing)\")\n",
    "    \n",
    "    # Sample image info\n",
    "    if image_files:\n",
    "        print(f\"\\n  Sample image info:\")\n",
    "        for img_path in image_files[:3]:\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                print(f\"    {img_path.name}: {img.size} pixels, mode={img.mode}\")\n",
    "            except Exception as e:\n",
    "                print(f\"    {img_path.name}: ERROR - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be9847",
   "metadata": {},
   "source": [
    "## 9. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994da071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (16, 12)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Disease Distribution (Bar chart)\n",
    "diseases = [d for d, _ in sorted_diseases]\n",
    "counts_list = [c for _, c in sorted_diseases]\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(diseases)))\n",
    "\n",
    "axes[0, 0].barh(diseases, counts_list, color=colors)\n",
    "axes[0, 0].set_xlabel('Number of Cases', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('Disease Distribution Across Dataset', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].invert_yaxis()\n",
    "\n",
    "for i, v in enumerate(counts_list):\n",
    "    axes[0, 0].text(v, i, f' {v:,}', va='center', fontsize=9)\n",
    "\n",
    "# Plot 2: Disease Percentage\n",
    "percentages = [(c/len(df)*100) for c in counts_list]\n",
    "axes[0, 1].bar(range(len(diseases)), percentages, color=colors)\n",
    "axes[0, 1].set_xticks(range(len(diseases)))\n",
    "axes[0, 1].set_xticklabels(diseases, rotation=45, ha='right')\n",
    "axes[0, 1].set_ylabel('Percentage (%)', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_title('Prevalence Rate (% of Dataset)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot 3: Diseases per Image\n",
    "disease_dist = df['num_diseases'].value_counts().sort_index()\n",
    "axes[1, 0].bar(disease_dist.index, disease_dist.values, color='steelblue', edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Number of Diseases per Image', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_title('Multi-Label Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 4: Class Weight Distribution (Log scale)\n",
    "weights = [class_weights[d] for d in diseases]\n",
    "axes[1, 1].barh(diseases, weights, color=colors)\n",
    "axes[1, 1].set_xlabel('Class Weight (Inverse Frequency)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_title('Recommended Class Weights for Training', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xscale('log')\n",
    "axes[1, 1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../results/01_eda_overview.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Visualizations saved to: results/01_eda_overview.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874ae39f",
   "metadata": {},
   "source": [
    "## 10. Sample Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29fd893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images with their labels\n",
    "image_dir = Config.RAW_DATA_DIR / 'images'\n",
    "\n",
    "if image_dir.exists() and len(list(image_dir.glob(\"*.png\"))) > 0:\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Get sample images with different disease counts\n",
    "    samples = [\n",
    "        df[df['num_diseases'] == 0].sample(1, random_state=42).iloc[0],  # Normal\n",
    "        df[df['num_diseases'] == 1].sample(1, random_state=42).iloc[0],  # Single disease\n",
    "        df[df['num_diseases'] == 2].sample(1, random_state=42).iloc[0],  # 2 diseases\n",
    "        df[df['num_diseases'] == 0].sample(1, random_state=43).iloc[0],\n",
    "        df[df['num_diseases'] == 1].sample(1, random_state=43).iloc[0],\n",
    "        df[df['num_diseases'] == 2].sample(1, random_state=43).iloc[0],\n",
    "        df[df['num_diseases'] == 0].sample(1, random_state=44).iloc[0],\n",
    "        df[df['num_diseases'] == 1].sample(1, random_state=44).iloc[0],\n",
    "        df[df['num_diseases'] == 2].sample(1, random_state=44).iloc[0],\n",
    "    ]\n",
    "    \n",
    "    for idx, (ax, sample) in enumerate(zip(axes, samples)):\n",
    "        image_id = sample.iloc[0]\n",
    "        image_path = image_dir / image_id\n",
    "        \n",
    "        labels = sample.iloc[1]\n",
    "        if pd.isna(labels):\n",
    "            labels = 'No Finding'\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(image_path)\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            ax.set_title(f\"ID: {image_id}\\nLabels: {labels}\", fontsize=9, wrap=True)\n",
    "            ax.axis('off')\n",
    "        except Exception as e:\n",
    "            ax.text(0.5, 0.5, f'Error loading:\\n{image_id}', ha='center')\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../../results/02_sample_images.png', dpi=200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ“ Sample images saved to: results/02_sample_images.png\")\n",
    "else:\n",
    "    print(\"âš ï¸  Images not available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aa8997",
   "metadata": {},
   "source": [
    "## 11. Stratification Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA STRATIFICATION STRATEGY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use disease count as stratification variable\n",
    "stratify_by = df['num_diseases']\n",
    "\n",
    "# Split: 70% train, 15% val, 15% test\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.3, \n",
    "    stratify=stratify_by,\n",
    "    random_state=42\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    ",\n",
    "\\nDataset Split:\")\n",
    "print(f\"  Training set: {len(train_df):,} images ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Validation set: {len(val_df):,} images ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Test set: {len(test_df):,} images ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nStratification Validation (Multi-label distribution):\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for num_dis in sorted(df['num_diseases'].unique()):\n",
    "    train_count = len(train_df[train_df['num_diseases'] == num_dis])\n",
    "    val_count = len(val_df[val_df['num_diseases'] == num_dis])\n",
    "    test_count = len(test_df[test_df['num_diseases'] == num_dis])\n",
    "    \n",
    "    total = train_count + val_count + test_count\n",
    "    train_pct = train_count/total*100 if total > 0 else 0\n",
    "    val_pct = val_count/total*100 if total > 0 else 0\n",
    "    test_pct = test_count/total*100 if total > 0 else 0\n",
    "    \n",
    "    print(f\"{num_dis} disease(s): Train {train_pct:.1f}% | Val {val_pct:.1f}% | Test {test_pct:.1f}%\")\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"\\nâœ“ Stratification successful - distributions preserved across splits!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14f1747",
   "metadata": {},
   "source": [
    "## 12. Class Imbalance Handling Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866a9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASS IMBALANCE MITIGATION STRATEGY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Based on EDA findings, here's the recommended approach:\n",
    "\n",
    "1. LOSS FUNCTION\n",
    "   âœ“ Use BCEWithLogitsLoss (for multi-label binary cross-entropy)\n",
    "   âœ“ Apply class weights (inverse frequency) from above\n",
    "   âœ“ Consider Focal Loss: reduces impact of easy negatives\n",
    "   \n",
    "2. SAMPLING STRATEGY\n",
    "   âœ“ Use WeightedRandomSampler during training\n",
    "   âœ“ Ensures each batch has balanced disease representation\n",
    "   âœ“ Prevents model overfitting to majority class\n",
    "   \n",
    "3. AUGMENTATION\n",
    "   âœ“ Apply stronger augmentation to minority classes\n",
    "   âœ“ Horizontal flip: safe for chest X-rays\n",
    "   âœ“ Rotation Â±15Â°, slight brightness/contrast changes\n",
    "   âœ“ Skip extreme augmentations (vertical flip, 90Â° rotation dangerous)\n",
    "   \n",
    "4. TRAINING CONFIGURATION\n",
    "   âœ“ Use stratified k-fold cross-validation\n",
    "   âœ“ Monitor per-class AUC-ROC (not just accuracy)\n",
    "   âœ“ Use macro-averaged F1 for evaluation\n",
    "   âœ“ Set decision threshold per class (don't use 0.5 for all)\n",
    "   \n",
    "5. VALIDATION METRICS\n",
    "   âœ“ Primary: Per-class AUC-ROC (target >0.80)\n",
    "   âœ“ Secondary: F1-score (macro and weighted)\n",
    "   âœ“ Supplementary: Precision, Recall per class\n",
    "   âœ“ Ignore: Accuracy (misleading with imbalanced data)\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34441f7a",
   "metadata": {},
   "source": [
    "## 13. Export Processed Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882ea444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splits directory\n",
    "splits_dir = project_root / 'data' / 'splits'\n",
    "splits_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save splits\n",
    "train_path = splits_dir / 'train.csv'\n",
    "val_path = splits_dir / 'val.csv'\n",
    "test_path = splits_dir / 'test.csv'\n",
    "\n",
    "train_df.to_csv(train_path, index=False)\n",
    "val_df.to_csv(val_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA SPLITS EXPORTED\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nâœ“ Training split: {train_path}\")\n",
    "print(f\"  Samples: {len(train_df):,}\")\n",
    "\n",
    "print(f\"\\nâœ“ Validation split: {val_path}\")\n",
    "print(f\"  Samples: {len(val_df):,}\")\n",
    "\n",
    "print(f\"\\nâœ“ Test split: {test_path}\")\n",
    "print(f\"  Samples: {len(test_df):,}\")\n",
    "\n",
    "print(f\"\\nâœ“ All splits saved to: {splits_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbd16dd",
   "metadata": {},
   "source": [
    "## 14. Summary & Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                    EXPLORATORY DATA ANALYSIS SUMMARY                         â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ğŸ“Š DATASET OVERVIEW\n",
    "   â€¢ Total Images: {len(df):,}\n",
    "   â€¢ Disease Classes: {len(sorted_diseases)} (excluding No Finding)\n",
    "   â€¢ Multi-label: {len(df[df['num_diseases'] > 1]):,} images ({len(df[df['num_diseases'] > 1])/len(df)*100:.1f}%)\n",
    "   â€¢ Normal findings: {images_with_no_finding:,} images ({images_with_no_finding/len(df)*100:.1f}%)\n",
    "\n",
    "âš ï¸  CLASS IMBALANCE SEVERITY\n",
    "   â€¢ Imbalance ratio: {imbalance_ratio:.1f}:1 (high)\n",
    "   â€¢ Gini coefficient: {gini:.4f} (significant inequality)\n",
    "   â€¢ Most prevalent: {sorted_diseases[0][0]} ({sorted_diseases[0][1]:,} cases)\n",
    "   â€¢ Least prevalent: {sorted_diseases[-1][0]} ({sorted_diseases[-1][1]:,} cases)\n",
    "\n",
    "ğŸ“ˆ MULTI-LABEL DISTRIBUTION\n",
    "   â€¢ Average diseases per image: {df['num_diseases'].mean():.2f}\n",
    "   â€¢ Single disease prevalence: {len(df[df['num_diseases']==1])/len(df)*100:.1f}%\n",
    "   â€¢ Multiple disease prevalence: {len(df[df['num_diseases']>1])/len(df)*100:.1f}%\n",
    "\n",
    "ğŸ”§ MITIGATION STRATEGIES IMPLEMENTED\n",
    "   âœ“ Stratified train/val/test split (preserves distribution)\n",
    "   âœ“ Inverse frequency class weights calculated\n",
    "   âœ“ Per-class evaluation metrics identified\n",
    "   âœ“ Balanced sampling strategy recommended\n",
    "\n",
    "ğŸ’¾ DATA READY FOR PREPROCESSING\n",
    "   âœ“ Metadata validated: {len(df):,} records\n",
    "   âœ“ Images verified: {len(list(image_dir.glob('*.png'))):,} files (if downloaded)\n",
    "   âœ“ Splits created: train/{len(train_df):,} | val/{len(val_df):,} | test/{len(test_df):,}\n",
    "   âœ“ Export location: {splits_dir}\n",
    "\n",
    "âš¡ NEXT STEPS\n",
    "   1. Create data loader using stratified splits\n",
    "   2. Implement class-weighted sampling in DataLoader\n",
    "   3. Configure loss function with class weights\n",
    "   4. Setup per-class evaluation metrics\n",
    "   5. Begin model training (preferably with focal loss)\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Save summary to file\n",
    "with open(project_root / 'docs' / 'EDA_REPORT.md', 'w') as f:\n",
    "    f.write(summary.replace('â•‘', '|').replace('â•”', '').replace('â•š', '').replace('â• ', '').replace('â•£', ''))\n",
    "\n",
    "print(f\"\\nâœ“ EDA Report saved to: docs/EDA_REPORT.md\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
